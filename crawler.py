import os
import requests
from bs4 import BeautifulSoup
import yt_dlp

# Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ
LINKS_DIR = "links"
VIDEOS_DIR = "videos"

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯
os.makedirs(LINKS_DIR, exist_ok=True)
os.makedirs(VIDEOS_DIR, exist_ok=True)

def extract_direct_mp4_links(url):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… mp4 Ø§Ø² ØµÙØ­Ù‡"""
    try:
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÚ¯â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ
        video_tags = soup.find_all("video")
        mp4_links = []
        
        for video in video_tags:
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ src
            src = video.get("src")
            if src and src.endswith(".mp4"):
                mp4_links.append(src)
                
            # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ¯â€ŒÙ‡Ø§ÛŒ source Ø¯Ø§Ø®Ù„ ÙˆÛŒØ¯ÛŒÙˆ
            sources = video.find_all("source")
            for source in sources:
                src = source.get("src")
                if src and src.endswith(".mp4"):
                    mp4_links.append(src)
                    
        return mp4_links
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ {url}: {e}")
        return []

def extract_video_links(url):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø§Ø² ÛŒÚ© ØµÙØ­Ù‡"""
    try:
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ {url}: {e}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    video_links = []

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ (Ù…Ø«Ù„Ø§Ù‹ mp4ØŒ m3u8 Ùˆ ÛŒÙˆØªÛŒÙˆØ¨)
    for tag in soup.find_all(["source", "iframe", "a"]):
        src = tag.get("src") or tag.get("href")
        if src and ("mp4" in src or "youtube.com" in src or "youtu.be" in src or "m3u8" in src):
            video_links.append(src)

    return video_links

def download_video(url):
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø§Ø² Ù„ÛŒÙ†Ú©"""
    ydl_opts = {
        'outtmpl': os.path.join(VIDEOS_DIR, '%(title)s.%(ext)s'),
        'format': 'best',
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            print(f"ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {url}")
            ydl.download([url])
        except Exception as e:
            print(f"âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø§Ù…ÙˆÙÙ‚ {url}: {e}")

def process_links():
    """Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§"""
    for filename in os.listdir(LINKS_DIR):
        if filename.endswith(".txt"):
            base_name = os.path.splitext(filename)[0]
            done_file = os.path.join(LINKS_DIR, f"{base_name}.done")
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„ done Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¬Ø¯Ø¯
            processed_links = set()
            if os.path.exists(done_file):
                with open(done_file, "r", encoding="utf-8") as f:
                    processed_links = set(line.strip() for line in f)

            filepath = os.path.join(LINKS_DIR, filename)
            video_output_dir = os.path.join(VIDEOS_DIR, base_name)
            os.makedirs(video_output_dir, exist_ok=True)

            with open(filepath, "r", encoding="utf-8") as f:
                links = [line.strip() for line in f.readlines() if line.strip()]

            new_processed_links = set()
            for link in links:
                if link in processed_links:
                    print(f"â­ï¸ Ù„ÛŒÙ†Ú© Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡: {link}")
                    continue

                print(f"ğŸ” Ø¨Ø±Ø±Ø³ÛŒ: {link}")
                video_links = extract_direct_mp4_links(link)
                
                if not video_links:
                    # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªÚ¯ video Ø¯Ø± HTML
                    response = requests.get(link, headers={"User-Agent": "Mozilla/5.0"})
                    soup = BeautifulSoup(response.text, "html.parser")
                    video_tags = soup.find_all("video")
                    for video in video_tags:
                        src = video.get("src")
                        if src:
                            video_links.append(src)

                if not video_links:
                    print(f"âŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ Ø¯Ø± {link}")
                else:
                    for video in video_links:
                        ydl_opts = {
                            'outtmpl': os.path.join(video_output_dir, '%(title)s.%(ext)s'),
                            'format': 'best',
                        }
                        download_video(video)
                    new_processed_links.add(link)

            # Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ done
            if new_processed_links:
                with open(done_file, "a", encoding="utf-8") as f:
                    for link in new_processed_links:
                        f.write(f"{link}\n")
                
            # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø³ØªÙˆØ± Ø¨Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§
            print(f"\nğŸ¤– Ø¯Ø³ØªÙˆØ± ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§:")
            print(f'python content_analyzer.py --directory "{video_output_dir}"')

if __name__ == "__main__":
    process_links()
